---
layout: post
title: ROS演習７：ロボットビジョン (cv_bridge)
date: 2016-11-11 14:48:12.000000000 +09:00
type: post
parent_id: '0'
published: true
password: ''
status: publish
categories:
- lecture
tags: []
meta:
  _edit_last: '2'
  views: '3802'
  _thumbnail_id: '13073'
author:
  login: demu
  email: info@demura.net
  display_name: demu
  first_name: ''
  last_name: ''
permalink: "/education/lecture/13067.html"
---
<p><a href="http://demura.net/wordpress/wp-content/uploads/2015/12/coke.jpg"><br />
</a> <a href="http://demura.net/wordpress/wp-content/uploads/2015/12/coke_can.jpg"><img src="{{ site.baseurl }}/assets/images/2016/11/coke_can.jpg" alt="coke_can" width="800" height="226" class="aligncenter size-large wp-image-12490" /></a></p>
<p>この記事は私が担当している講義ロボットプログラミングⅡ用です。今回はcv_bridgeを使います。ROSでOpenCVを使いgazeboシミュレータのRGB-Dセンサから取得した画像から赤色の抽出とエッジ抽出を行います。</p>
<p>この記事は、以下のROSチュートリアルと「ROSで始めるロボットプログラミング、小倉著」を参考にしています。</p>
<ul>
<li><a href="http://wiki.ros.org/cv_bridge/Tutorials/UsingCvBridgeToConvertBetweenROSImagesAndOpenCVImages">Converting between ROS images and OpenCV images (C++)</a></li>
</ul>
<p>ソース：ROSのチュートリアルと「ROSで始めるロボットプログラミング」をベースに改変しています。</p>
<pre class="brush:cpp;"> 
#include &#60;ros/ros.h&#62;
#include &#60;image_transport/image_transport.h&#62;
#include &#60;cv_bridge/cv_bridge.h&#62;
#include &#60;sensor_msgs/image_encodings.h&#62;
#include &#60;opencv2/imgproc/imgproc.hpp&#62;
#include &#60;opencv2/highgui/highgui.hpp&#62;

static const std::string OPENCV_WINDOW = "Image window";

class ImageConverter
{
  ros::NodeHandle nh_;
  image_transport::ImageTransport it_;
  image_transport::Subscriber image_sub_;
  image_transport::Publisher image_pub_;

public:
  // コンストラクタ
　ImageConverter()
    : it_(nh_)
  {
    // カラー画像をサブスクライブ                                                                
    image_sub_ = it_.subscribe("/camera/rgb/image_raw", 1,
      &amp;ImageConverter::imageCb, this);
    // 処理した画像をパブリッシュ                                                                                          
    image_pub_ = it_.advertise("/image_topic", 1);
 }

  // デストラクタ
  ~ImageConverter()
  {
    cv::destroyWindow(OPENCV_WINDOW);
  }

  // コールバック関数
  void imageCb(const sensor_msgs::ImageConstPtr&amp; msg)
  {
    cv_bridge::CvImagePtr cv_ptr, cv_ptr2, cv_ptr3;
 try
    {
      // ROSからOpenCVの形式にtoCvCopy()で変換。cv_ptr-&#62;imageがcv::Matフォーマット。
      cv_ptr    = cv_bridge::toCvCopy(msg, sensor_msgs::image_encodings::BGR8);
      cv_ptr3   = cv_bridge::toCvCopy(msg, sensor_msgs::image_encodings::MONO8);
    }
    catch (cv_bridge::Exception&amp; e)
    {
      ROS_ERROR("cv_bridge exception: %s", e.what());
      return;
    }

    cv::Mat hsv_image, color_mask, gray_image, cv_image2, cv_image3;
    // RGB表色系をHSV表色系へ変換して、hsv_imageに格納
    cv::cvtColor(cv_ptr-&#62;image, hsv_image, CV_BGR2HSV);

    // 色相(Hue), 彩度(Saturation), 明暗(Value, brightness) 
    // 指定した範囲の色でマスク画像color_mask(CV_8U:符号なし8ビット整数)を生成  
    // マスク画像は指定した範囲の色に該当する要素は255(8ビットすべて1)、それ以外は0                                                      
    cv::inRange(hsv_image, cv::Scalar(150, 100, 50, 0) , cv::Scalar(180, 255, 255, 0), color_mask);
    // ビット毎の論理積。マスク画像は指定した範囲以外は0で、指定範囲の要素は255なので、ビット毎の論理積を適用すると、指定した範囲の色に対応する要素はそのままで、他は0になる。
    cv::bitwise_and(cv_ptr-&#62;image, cv_ptr-&#62;image, cv_image2, color_mask);
    // グレースケールに変換
    cv::cvtColor(cv_ptr-&#62;image, gray_image, CV_BGR2GRAY);
    // エッジを検出するためにCannyアルゴリズムを適用
    cv::Canny(gray_image, cv_ptr3-&#62;image, 15.0, 30.0, 3);

    // ウインドウに円を描画                                                
    cv::circle(cv_ptr-&#62;image, cv::Point(100, 100), 20, CV_RGB(0,255,0));

    // 画像サイズは縦横半分に変更
    cv::Mat cv_half_image, cv_half_image2, cv_half_image3;
    cv::resize(cv_ptr-&#62;image, cv_half_image,cv::Size(),0.5,0.5);
    cv::resize(cv_image2, cv_half_image2,cv::Size(),0.5,0.5);
    cv::resize(cv_ptr3-&#62;image, cv_half_image3,cv::Size(),0.5,0.5);

    // ウインドウ表示                                                                         
    cv::imshow("Original Image", cv_half_image);
    cv::imshow("Result Image", cv_half_image2);
    cv::imshow("Edge Image", cv_half_image3);
    cv::waitKey(3);
 
    // エッジ画像をパブリッシュ。OpenCVからROS形式にtoImageMsg()で変換。                                                            
    image_pub_.publish(cv_ptr3-&#62;toImageMsg());
  }
};

int main(int argc, char** argv)
{
  ros::init(argc, argv, "image_converter");
  ImageConverter ic;
  ros::spin();
  return 0;
}
</pre>
<p>&nbsp;</p>
<p>1A 簡単な準備：時間のない方は以下で準備してください。CMakeLists.txtやPackage.xmlを編集する必要がありません。</p>
<ul>
<li>以下のファイルを~/catkin_ws/srcの下にコピーする
<ul>
<li><a href="http://demura.net/wordpress/wp-content/uploads/2015/12/cv_bridge_tutorial2.tgz">cv_bridge_tutorial.tgz</a></li>
</ul>
</li>
<li>$ cd ~/catkin_ws/src</li>
<li>$ tar xvzf cv_bridge_tutorial.tgz</li>
<li>$ cd ~/catkin_ws</li>
<li>$ catkin_make</li>
</ul>
<p>自分でCMakeLists.txtやPackage.xmlを編集したい方は次の準備を実施してください。それ以外は2の実行をやろう！</p>
<p>1B 準備</p>
<p>$ cd ~/catkin_ws/src<br />
$ catkin_create_pkg cv_bridge_tutorial sensor_msgs opencv2 cv_bridge roscpp std_msgs<br />
$ cd cv_bridge_tutorial/src<br />
$ gedit cv_bridge_tutorial.cpp<br />
上のソースコードをgeditにコピペして保存する。<br />
$ cd ~/cakin_ws<br />
$ catkin_make<br />
catkin_makeでエラーが出る場合、CMakeLists.txtのfind_packageにopencv2のパッケージを入れている場合は削除してください。既に入っているので必用ありません。</p>
<p>2 実行</p>
<ul>
<li>$ roslaunch turtlebot_gazebo turtlebot_world.launch</li>
<li>$ rosrun cv_bridge_tutorial cv_bridge_tutorial</li>
<li>次のコマンドでロボットを動かしてカメラ画像が変わるのを確認しよう
<ul>
<li>$ roslaunch turtlebot_teleop keyboard_teleop.launch</li>
</ul>
</li>
</ul>
<p>演　習</p>
<ul>
<li>シミュレータにコカ・コーラの缶(Coke Can)を挿入して、それを追うプログラムを作ろう</li>
<li>コーラ缶を挿入するためにはGazeboのInsertタブをクリックして、その中のCoke Canを選択して、Gazebo上の配置したい場所をクリックするとそこに現れます。</li>
</ul>
<p>終わり</p>
